env_config:
  collector: "container"
  env_id: "motion_control_continuous_events-v0"
  seed: 14
  stack_frame: 1   # span 1, 4, 8
  kwargs:
    world_name: "world_0.world"
    gui: false
    verbose: false
    max_step: 400
    time_step: 0.2
    slack_reward: 0
    collision_reward: -1
    failure_reward: 0
    success_reward: 20
    goal_reward: 1
    max_collision: 1
    init_position: [-2, 3, 1.57]
    goal_position: [0, 10, 0]

    event_clip: 1024
    min_v: -1
    max_v: 2
    min_w: -3.14
    max_w: 3.14

training_config:
  algorithm: "SAC"
  encoder: "mlp"  # span "mlp", "cnn", "rnn", "transformer"
  buffer_size: 200000
  actor_lr: 0.00001
  critic_lr: 0.00002
  # For head
  num_layers: 1
  hidden_layer_size: 512
  # For encoder
  encoder_num_layers: 2
  encoder_hidden_layer_size: 512
  exploration_noise_start: 0.1
  exploration_noise_end: 0.0999
  pre_collect: 4096
  log_intervals: 2

  policy_args:
    tau: 0.005
    gamma: 0.99
    policy_noise: 0.2
    update_actor_freq: 2
    noise_clip: 0.5
    n_step: 4

  training_args:
    max_step: 4000000
    collect_per_step: 4096
    update_per_step: 1024
    batch_size: 128

container_config:
  # 1 container running in parallel
  num_actor: 1
  # 10 training static world
  worlds: [40, 16, 37, 45, 42, 39, 1, 22, 44, 6]
  # 40 test static worlds
  test_worlds: [18, 7, 3, 24, 25, 35, 28, 26, 32, 5, 14, 8, 21, 9, 46, 12, 11, 19, 34, 47, 43, 38, 23, 15, 4, 20, 41, 33, 48, 10, 17, 31, 29, 13, 0, 49, 30, 27, 2, 36]
